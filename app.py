import os
import time
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
import torch
import torch.nn as nn


# --- [1. ì„¤ì • ë° ëª¨ë¸ ì •ì˜] ---
# (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ í•„ìˆ˜)
SENSOR_COLUMNS = ["force_x", "force_y", "force_z", "vibration_x", "vibration_y", "vibration_z", "ae_rms"]
MODEL_PATH = "artifacts/models/best_anomaly_model.pth"
DATA_ROOT = "data/phm2010"
TRAIN_CONDITIONS = ["c1", "c4", "c6"]
SEQ_LEN = 50
HIDDEN_SIZE = 64  # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ hidden sizeì™€ ë™ì¼í•˜ê²Œ ìœ ì§€
STRIDE = 5
DOWNSAMPLE_FACTOR = 2  # í•™ìŠµ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬
THRESHOLD_DEFAULT = 0.0674


class Seq2SeqAutoencoder(nn.Module):
    def __init__(self, input_dim, seq_len, hidden_size, num_layers=2):
        super().__init__()
        self.seq_len = seq_len
        self.input_dim = input_dim
        self.encoder = nn.LSTM(input_dim, hidden_size, num_layers, batch_first=True)
        self.decoder = nn.LSTM(input_dim, hidden_size, num_layers, batch_first=True)
        self.output_layer = nn.Linear(hidden_size, input_dim)

    def forward(self, x):
        batch_size = x.size(0)
        _, (hidden, cell) = self.encoder(x)
        decoder_input = torch.zeros(batch_size, self.seq_len, self.input_dim, device=x.device, dtype=x.dtype)
        decoded, _ = self.decoder(decoder_input, (hidden, cell))
        return self.output_layer(decoded)


# í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ë§¨ ì²˜ìŒì— ì™€ì•¼ í•¨)
st.set_page_config(page_title="CNC AI ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ", layout="wide", page_icon="ğŸ­")

if "is_running" not in st.session_state:
    st.session_state["is_running"] = False
if "current_step" not in st.session_state:
    st.session_state["current_step"] = 0
if "chart_history_score" not in st.session_state:
    st.session_state["chart_history_score"] = []
if "chart_history_threshold" not in st.session_state:
    st.session_state["chart_history_threshold"] = []
if "last_rendered_step" not in st.session_state:
    st.session_state["last_rendered_step"] = -1


def reset_simulation_state():
    st.session_state["current_step"] = 0
    st.session_state["chart_history_score"] = []
    st.session_state["chart_history_threshold"] = []
    st.session_state["last_rendered_step"] = -1

# --- [2. ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ (ìºì‹± ì ìš©)] ---
@st.cache_resource
def load_ai_model(model_path, input_dim, seq_len, hidden_size):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Seq2SeqAutoencoder(input_dim, seq_len, hidden_size).to(device)
    if os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint["model_state"])
        model.eval()
        return model, device
    else:
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None, None


@st.cache_resource
def compute_global_min_max(train_conditions, downsample):
    """í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì¡°ê±´ë“¤ ì „ì²´ì— ëŒ€í•œ ì „ì—­ min/maxë¥¼ ê³„ì‚°."""
    global_min = None
    global_max = None
    data_dir = Path(DATA_ROOT)

    for condition in train_conditions:
        cond_dir = data_dir / condition
        csv_files = sorted(cond_dir.glob("*.csv"))
        for csv in csv_files:
            for chunk in pd.read_csv(csv, header=None, names=SENSOR_COLUMNS, chunksize=200_000):
                if downsample > 1:
                    chunk = chunk.iloc[::downsample]
                values = chunk.values
                if global_min is None:
                    global_min = values.min(axis=0)
                    global_max = values.max(axis=0)
                else:
                    global_min = np.minimum(global_min, values.min(axis=0))
                    global_max = np.maximum(global_max, values.max(axis=0))

    if global_min is None or global_max is None:
        raise RuntimeError("ì „ì—­ min/maxë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    data_range = np.maximum(global_max - global_min, 1e-8)
    return global_min, data_range


def normalize_with_stats(values, global_min, data_range):
    return (values - global_min) / data_range


def build_sequences(array, seq_len, stride):
    total = (len(array) - seq_len) // stride + 1
    if total <= 0:
        return np.empty((0, seq_len, array.shape[1]), dtype=array.dtype)
    sequences = np.zeros((total, seq_len, array.shape[1]), dtype=array.dtype)
    for idx, start in enumerate(range(0, len(array) - seq_len + 1, stride)):
        sequences[idx] = array[start : start + seq_len]
    return sequences


@st.cache_data
def load_and_process_data(condition, _model, _device, seq_len, stride=STRIDE, downsample=DOWNSAMPLE_FACTOR):
    """
    ì„ íƒëœ ì¡°ê±´(c1~c6)ì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ëª¨ë¸ì„ ëŒë ¤ ë¯¸ë¦¬ ì—ëŸ¬(Anomaly Score)ë¥¼ ê³„ì‚°í•´ ë‘¡ë‹ˆë‹¤.
    ì‹¤ì‹œê°„ ë£¨í”„ì—ì„œ ë§¤ë²ˆ ì¶”ë¡ í•˜ë©´ ëŠë¦¬ê¸° ë•Œë¬¸ì—, ì‹œë®¬ë ˆì´í„°ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    data_dir = Path(DATA_ROOT) / condition
    csv_files = sorted(data_dir.glob("*.csv"))

    if not csv_files:
        return None, None

    # ë°ì´í„° ë¡œë“œ (í•™ìŠµê³¼ ë™ì¼í•œ ë‹¤ìš´ìƒ˜í”Œ)
    frames = []
    for p in csv_files:
        df = pd.read_csv(p, header=None, names=SENSOR_COLUMNS)
        if downsample > 1:
            df = df.iloc[::downsample]
        frames.append(df)

    full_df = pd.concat(frames, ignore_index=True)

    global_min, data_range = compute_global_min_max(TRAIN_CONDITIONS, downsample)
    normalized = normalize_with_stats(full_df.values, global_min, data_range)

    sequences = build_sequences(normalized, seq_len, stride)
    if len(sequences) == 0:
        return None, None

    # ëŒ€ëŸ‰ í…ì„œë¥¼ í•œ ë²ˆì— GPUë¡œ ì˜®ê¸°ë©´ VRAMì„ ì´ˆê³¼í•˜ë¯€ë¡œ CPUì— ë‘ê³  ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì „ì†¡
    seq_tensor = torch.tensor(sequences, dtype=torch.float32)

    # ì¶”ë¡  (Batch ì²˜ë¦¬)
    batch_size = 512
    errors = []
    criterion = nn.L1Loss(reduction="none")

    with torch.no_grad():
        for i in range(0, len(seq_tensor), batch_size):
            batch = seq_tensor[i: i + batch_size].to(_device, non_blocking=True)
            recon = _model(batch)
            loss = criterion(recon, batch).mean(dim=(1, 2)).cpu().numpy()
            errors.extend(loss)

    return full_df, np.array(errors)


# --- [3. ë©”ì¸ UI êµ¬ì„±] ---
st.title("ğŸ­ CNC ì¥ë¹„ ìƒíƒœ ë¶„ì„ ë° ì˜ˆì§€ë³´ì „ ì‹œìŠ¤í…œ")
st.markdown("---")

# ì‚¬ì´ë“œë°”: ì œì–´ íŒ¨ë„
with st.sidebar:
    st.header("âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •")
    selected_condition = st.selectbox("ë°ì´í„° ì„ íƒ (Scenario)", ["c1", "c4", "c6", "c2", "c3", "c5"], index=3)  # c2 ê¸°ë³¸

    st.subheader("ëª¨ë¸ íŒŒë¼ë¯¸í„°")
    threshold = st.number_input(
        "ì´ìƒì¹˜ ì„ê³„ê°’ (Threshold)",
        value=THRESHOLD_DEFAULT,
        step=0.001,
        format="%.4f",
    )

    st.subheader("ì¬ìƒ ì†ë„ ì œì–´")
    speed = st.slider("ì‹œë®¬ë ˆì´ì…˜ ì†ë„", 1, 100, 10)

    start_btn = st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘", type="primary")
    pause_btn = st.button("â¸ï¸ ì¼ì‹œì •ì§€")
    reset_btn = st.button("ğŸ”„ ì´ˆê¸°í™”")

# ëª¨ë¸ ë¡œë“œ
model, device = load_ai_model(MODEL_PATH, input_dim=len(SENSOR_COLUMNS), seq_len=SEQ_LEN, hidden_size=HIDDEN_SIZE)
if model is None or device is None:
    st.stop()

if start_btn:
    st.session_state['is_running'] = True
if pause_btn:
    st.session_state['is_running'] = False
if reset_btn:
    st.session_state['is_running'] = False
    reset_simulation_state()

# ë°ì´í„° ì¤€ë¹„
if 'data_cache' not in st.session_state or st.session_state.get('last_cond') != selected_condition:
    with st.spinner(f"{selected_condition} ë°ì´í„° ë° AI ë¶„ì„ ê²°ê³¼ ë¡œë”© ì¤‘..."):
        raw_df, error_scores = load_and_process_data(
            selected_condition,
            model,
            device,
            seq_len=SEQ_LEN,
            stride=STRIDE,
            downsample=DOWNSAMPLE_FACTOR,
        )
        st.session_state['data_cache'] = (raw_df, error_scores)
        st.session_state['last_cond'] = selected_condition
        st.session_state['is_running'] = False
        reset_simulation_state()
else:
    raw_df, error_scores = st.session_state['data_cache']

# --- [4. ëŒ€ì‹œë³´ë“œ ë·° êµ¬í˜„] ---

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ–¥ï¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ğŸ”® ì˜ˆì¸¡ ë° ì§„ë‹¨", "ğŸ” ì‹¬ì¸µ ë¶„ì„", "ğŸ’° ìš´ì˜ ìµœì í™”"])

with tab1:
    st.markdown("### ğŸ“Š ì‹¤ì‹œê°„ ì„¼ì„œ ë°ì´í„° ë° ì´ìƒ ê°ì§€ í˜„í™©")
    kpi_container = st.empty()
    st.markdown("---")
    chart_placeholder = st.empty()
    log_placeholder = st.empty()

with tab2:
    pred_col1, pred_col2 = st.columns(2)
    rul_chart_placeholder = st.empty()

with tab3:
    st.info("ì´ ê¸°ëŠ¥ì€ íŠ¹ì • ì‹œì ì˜ ìƒì„¸ FFT ë¶„ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    analysis_col1, analysis_col2 = st.columns(2)

with tab4:
    roi_col1, roi_col2, roi_col3 = st.columns(3)

progress_bar = st.progress(0)


def update_dashboard(step_idx, threshold_value, append_history=True):
    if error_scores is None or len(error_scores) == 0:
        return

    total_steps = len(error_scores)
    step_idx = int(max(0, min(step_idx, total_steps - 1)))
    current_score = float(error_scores[step_idx])

    chart_scores = st.session_state['chart_history_score']
    chart_thresholds = st.session_state['chart_history_threshold']
    last_step = st.session_state.get('last_rendered_step', -1)

    if append_history and step_idx != last_step:
        chart_scores.append(current_score)
        chart_thresholds.append(threshold_value)
        if len(chart_scores) > 200:
            chart_scores[:] = chart_scores[-200:]
            chart_thresholds[:] = chart_thresholds[-200:]
        st.session_state['last_rendered_step'] = step_idx
    elif not chart_scores:
        chart_scores.append(current_score)
        chart_thresholds.append(threshold_value)
    elif not append_history and chart_thresholds:
        chart_thresholds[-1] = threshold_value

    plot_score = chart_scores[-200:]
    plot_threshold = chart_thresholds[-200:] if chart_thresholds else [threshold_value] * len(plot_score)

    is_danger = current_score > threshold_value
    status_text = "ğŸš¨ ìœ„í—˜ (Danger)" if is_danger else "âœ… ì •ìƒ (Normal)"
    status_color = "red" if is_danger else "green"

    with kpi_container.container():
        kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)

        with kpi_col1:
            approx_cut = int((step_idx * STRIDE) / SEQ_LEN) + 1
            st.metric(label="í˜„ì¬ ì‘ì—… (Cut)", value=f"#{approx_cut}")

        with kpi_col2:
            st.metric(
                label="ì´ìƒ ì ìˆ˜ (Anomaly Score)",
                value=f"{current_score:.4f}",
                delta=f"{current_score - threshold_value:.4f}",
                delta_color="inverse",
            )

        with kpi_col3:
            temp_val = 40 + (step_idx / max(total_steps, 1)) * 15
            st.metric(label="í˜„ì¬ ì˜¨ë„ (Temp)", value=f"{temp_val:.1f} Â°C")

        with kpi_col4:
            st.markdown("#### ìƒíƒœ")
            st.markdown(f":{status_color}[**{status_text}**]")

    chart_df = pd.DataFrame({
        "Anomaly Score": plot_score,
        "Threshold": plot_threshold if len(plot_threshold) == len(plot_score) else [threshold_value] * len(plot_score),
    })
    chart_placeholder.line_chart(chart_df, color=["#0000FF", "#FF0000"], height=350)

    if is_danger:
        log_placeholder.error(f"âš ï¸ [WARNING] ì´ìƒ ê°ì§€ë¨! ì ìˆ˜: {current_score:.4f} > ì„ê³„ê°’: {threshold_value}")
    else:
        log_placeholder.empty()

    remaining_steps = total_steps - step_idx
    rul_cuts = int(max(0, remaining_steps) / 50)
    wear_percent = min(100.0, (step_idx / max(total_steps - 1, 1)) * 100)

    with pred_col1:
        st.metric("ë‚¨ì€ ìˆ˜ëª… (RUL)", f"{rul_cuts} íšŒ (Cuts)")
    with pred_col2:
        st.metric("í˜„ì¬ ë§ˆëª¨ìœ¨", f"{wear_percent:.1f} %")

    with rul_chart_placeholder.container():
        st.progress(wear_percent / 100, text=f"ë§ˆëª¨ ì§„í–‰ë„: {wear_percent:.1f}%")

    if step_idx % 10 == 0:
        with analysis_col1:
            importance_data = pd.DataFrame({
                "Sensor": ["Vibration_Z", "Vibration_Y", "AE_RMS", "Force_X", "Force_Z"],
                "Importance": [0.35, 0.25, 0.20, 0.15, 0.05]
            })
            st.bar_chart(importance_data.set_index("Sensor"))
            st.caption("í•µì‹¬ ê¸°ì—¬ ì„¼ì„œ (Top 5)")

    cost_saved = int((step_idx / 100) * 5)
    with roi_col1:
        st.metric("ì¶”ì²œ êµì²´ ì‹œì ", "RUL 30íšŒ ë¯¸ë§Œ")
    with roi_col2:
        st.metric("ì˜ˆìƒ ì ˆê° ë¹„ìš©", f"{cost_saved} ë§Œì›")
    with roi_col3:
        rec_text = "ì‚¬ìš© ê°€ëŠ¥"
        if rul_cuts < 30:
            rec_text = "êµì²´ ê¶Œì¥"
        if rul_cuts < 10:
            rec_text = "ì¦‰ì‹œ êµì²´ í•„ìš”"
        st.metric("AI ì œì•ˆ", rec_text)

    progress_bar.progress(min(1.0, step_idx / max(total_steps - 1, 1)))

# --- [5. ì‹¤ì‹œê°„ ë£¨í”„ (Animation Loop)] ---
if error_scores is not None:
    total_steps = len(error_scores)
    current_step = min(st.session_state.get('current_step', 0), total_steps - 1)

    if st.session_state.get('is_running'):
        next_step = min(current_step + speed, total_steps - 1)
        update_dashboard(next_step, threshold, append_history=True)
        st.session_state['current_step'] = next_step

        if next_step >= total_steps - 1:
            st.session_state['is_running'] = False
            st.success("ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")
        else:
            time.sleep(0.05)
            st.rerun()
    else:
        update_dashboard(current_step, threshold, append_history=False)
        if current_step >= total_steps - 1:
            st.success("ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")
else:
    st.info("ì„ íƒí•œ ì¡°ê±´ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")