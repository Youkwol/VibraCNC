from __future__ import annotations

import json
from pathlib import Path

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from vibracnc.anomaly.autoencoder import load_model
from vibracnc.anomaly.pipeline import score_with_artifacts
from vibracnc.config import DatasetConfig
from vibracnc.data.loader import discover_csv_files, load_csv
from vibracnc.data.preprocessing import WindowingConfig, dataframe_to_windows
from vibracnc.workflows import load_anomaly_artifacts

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="VibraCNC ë¶„ì„ ë¦¬í¬íŠ¸",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
DEFAULT_MONITORING_PATH = Path("artifacts/monitoring/monitoring_report.json")
DEFAULT_DIAGNOSTICS_PATH = Path("artifacts/monitoring/diagnostics_report.json")
DEFAULT_ANALYSIS_PATH = Path("artifacts/monitoring/analysis_report.json")
DEFAULT_MODELS_DIR = Path("artifacts/models")
DEFAULT_FIGURES_DIR = Path("artifacts/figures")
DEFAULT_DATASET_DIR = Path("data/phm2010")


@st.cache_data(show_spinner=False)
def load_static_condition_data(
    dataset_dir: str,
    models_dir: str,
    condition: str,
    num_cuts: int,
    sampling_rate: float,
    window_seconds: float,
    step_seconds: float,
) -> tuple[list[dict], float]:
    dataset_root = Path(dataset_dir)
    models_path = Path(models_dir)
    dataset_config = DatasetConfig(
        root_dir=dataset_root,
        sampling_rate=sampling_rate,
        window_seconds=window_seconds,
        step_seconds=step_seconds,
    )
    window_config = WindowingConfig.from_seconds(
        window_seconds=window_seconds,
        step_seconds=step_seconds,
        sampling_rate=sampling_rate,
    )

    artifacts = load_anomaly_artifacts(models_path / "anomaly_artifacts.json")
    model = load_model(models_path / "anomaly_autoencoder.pt", artifacts.config)

    csv_files = discover_csv_files(dataset_root / condition)
    if num_cuts is not None:
        csv_files = csv_files[:num_cuts]

    records: list[dict] = []
    for idx, path in enumerate(csv_files, start=1):
        frame = load_csv(path, column_names=dataset_config.resolve_column_names())
        errors = score_with_artifacts(
            model,
            [frame],
            dataset_config.fft_columns,
            window_config,
            artifacts,
        )
        score = float(np.mean(errors))
        vibration_values = frame[list(dataset_config.fft_columns)].to_numpy(dtype=float)
        vibration_rms = float(np.sqrt(np.mean(np.square(vibration_values))))

        records.append(
            {
                "cut": idx,
                "file": path.name,
                "score": score,
                "is_anomaly": bool(score > artifacts.threshold),
                "vibration_rms": vibration_rms,
            }
        )

    return records, float(artifacts.threshold)


@st.cache_data(show_spinner=False)
def compute_fft_spectrum(
    dataset_dir: str,
    condition: str,
    cut_index: int,
    sampling_rate: float,
    window_seconds: float,
    step_seconds: float,
    fft_columns: tuple[str, ...],
) -> tuple[list[float], list[float], str] | None:
    dataset_root = Path(dataset_dir)
    dataset_config = DatasetConfig(
        root_dir=dataset_root,
        sampling_rate=sampling_rate,
        window_seconds=window_seconds,
        step_seconds=step_seconds,
    )
    window_config = WindowingConfig.from_seconds(
        window_seconds=window_seconds,
        step_seconds=step_seconds,
        sampling_rate=sampling_rate,
    )
    files = discover_csv_files(dataset_root / condition)
    if cut_index < 1 or cut_index > len(files):
        return None

    path = files[cut_index - 1]
    frame = load_csv(path, column_names=dataset_config.resolve_column_names())
    frequencies, amplitudes = dataframe_to_windows(frame, fft_columns, window_config)
    spectrum = amplitudes.mean(axis=(0, 2))
    return frequencies.tolist(), spectrum.tolist(), path.name


def render_static_condition_section(
    records: list[dict],
    threshold: float,
    condition: str,
    fft_payload: tuple[list[float], list[float], str] | None,
    selected_cut: int,
    freq_band: tuple[int, int],
):
    st.header("ğŸ“Œ Cut ê¸°ë°˜ ì •ì  ë¶„ì„")

    if not records:
        st.info("ì„ íƒí•œ ì¡°ê±´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì»· ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(records)
    selected_cut = min(max(selected_cut, 1), len(df))

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ Cut ìˆ˜", len(df))
    with col2:
        st.metric("ì´ìƒ íƒì§€ ìˆ˜", int(df["is_anomaly"].sum()))
    with col3:
        ratio = df["is_anomaly"].mean() * 100 if len(df) > 0 else 0.0
        st.metric("ì´ìƒ ë¹„ìœ¨", f"{ratio:.1f}%")
    with col4:
        st.metric("ì„ê³„ê°’", f"{threshold:.4f}")

    st.subheader("1) ìœ„í—˜ ì ìˆ˜ ì¶”ì´")
    fig_risk = go.Figure()
    fig_risk.add_trace(
        go.Scatter(
            x=df["cut"],
            y=df["score"],
            mode="lines+markers",
            name="ìœ„í—˜ ì ìˆ˜",
            line=dict(color="#1f77b4"),
        )
    )
    anomaly_df = df[df["is_anomaly"]]
    if not anomaly_df.empty:
        fig_risk.add_trace(
            go.Scatter(
                x=anomaly_df["cut"],
                y=anomaly_df["score"],
                mode="markers",
                name="ì´ìƒ Cut",
                marker=dict(color="#d62728", size=8),
            )
        )
    fig_risk.add_hline(
        y=threshold,
        line_dash="dash",
        line_color="orange",
        annotation_text=f"Threshold {threshold:.4f}",
    )
    fig_risk.update_layout(
        xaxis_title="Cut ë²ˆí˜¸",
        yaxis_title="ìœ„í—˜ ì ìˆ˜",
        height=350,
    )
    st.plotly_chart(fig_risk, use_container_width=True)

    st.subheader("2) í‰ê·  ì§„ë™ ì„¸ê¸° (RMS)")
    fig_rms = px.line(
        df,
        x="cut",
        y="vibration_rms",
        markers=True,
        labels={"cut": "Cut ë²ˆí˜¸", "vibration_rms": "ì§„ë™ RMS"},
        title="í‰ê·  ì§„ë™ ì„¸ê¸° ì¶”ì´",
    )
    fig_rms.update_layout(height=300)
    st.plotly_chart(fig_rms, use_container_width=True)

    st.subheader("3) ê³ ì¥ ì›ì¸ ì£¼íŒŒìˆ˜ ë¶„ì„")
    if fft_payload is None:
        st.info("ì„ íƒí•œ Cutì— ëŒ€í•œ FFT ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    frequencies, spectrum, file_name = fft_payload
    freq_min, freq_max = freq_band
    highlight = [
        freq_min <= freq <= freq_max for freq in frequencies
    ]
    colors = ["#ef553b" if flag else "#636efa" for flag in highlight]

    fig_fft = go.Figure(
        go.Bar(
            x=frequencies,
            y=spectrum,
            marker_color=colors,
            name="Amplitude",
        )
    )
    fig_fft.update_layout(
        title=f"FFT ìŠ¤í™íŠ¸ëŸ¼ - Cut {selected_cut} ({file_name})",
        xaxis_title="Frequency (Hz)",
        yaxis_title="Amplitude",
        height=400,
    )
    st.plotly_chart(fig_fft, use_container_width=True)


def load_json(path: Path) -> dict | None:
    """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not path.exists():
        return None
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None


def render_anomaly_detection_section(monitoring_data: dict, models_dir: Path):
    """ì´ìƒ íƒì§€ ë¶„ì„ ì„¹ì…˜"""
    st.header("ğŸ” ì´ìƒ íƒì§€ ë¶„ì„")
    
    st.subheader("1. ì´ìƒ íƒì§€ ëª¨ë¸ ê°œìš”")
    
    # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    metadata_path = models_dir / "anomaly_artifacts.json"
    if metadata_path.exists():
        metadata = load_json(metadata_path)
        if metadata:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì„ê³„ê°’", f"{metadata.get('threshold', 0):.6f}")
            with col2:
                config = metadata.get("config", {})
                st.metric("ì…ë ¥ ì°¨ì›", config.get("input_dim", "N/A"))
            with col3:
                st.metric("ì€ë‹‰ ì°¨ì›", config.get("hidden_dim", "N/A"))
            
            # í•™ìŠµ íˆìŠ¤í† ë¦¬
            train_history = metadata.get("train_history", {})
            if train_history:
                st.subheader("2. ëª¨ë¸ í•™ìŠµ ê³¼ì •")
                epochs = range(1, len(train_history.get("train_loss", [])) + 1)
                df_history = pd.DataFrame({
                    "epoch": epochs,
                    "train_loss": train_history.get("train_loss", []),
                    "val_loss": train_history.get("val_loss", []),
                })
                fig_history = go.Figure()
                fig_history.add_trace(
                    go.Scatter(x=df_history["epoch"], y=df_history["train_loss"], 
                             mode="lines", name="Train Loss", line=dict(color="blue"))
                )
                if df_history["val_loss"].notna().any():
                    fig_history.add_trace(
                        go.Scatter(x=df_history["epoch"], y=df_history["val_loss"], 
                                 mode="lines", name="Validation Loss", line=dict(color="red"))
                    )
                fig_history.update_layout(
                    title="í•™ìŠµ ì†ì‹¤ ì¶”ì´",
                    xaxis_title="Epoch",
                    yaxis_title="Loss",
                    height=400,
                )
                st.plotly_chart(fig_history, width="stretch")
    
    # í˜„ì¬ ìƒíƒœ ë¶„ì„
    current = monitoring_data.get("current_state", {})
    series = monitoring_data.get("series", {})
    anomaly_scores = series.get("anomaly_scores", [])
    
    if anomaly_scores:
        st.subheader("3. ì´ìƒ íƒì§€ ê²°ê³¼ ë¶„ì„")
        
        df_anomaly = pd.DataFrame(anomaly_scores)
        threshold = current.get("threshold", 0.0)
        
        # í†µê³„ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_cuts = len(df_anomaly)
            st.metric("ì´ Cut ìˆ˜", total_cuts)
        with col2:
            anomaly_count = df_anomaly["is_anomaly"].sum()
            st.metric("ì´ìƒ íƒì§€ ìˆ˜", anomaly_count)
        with col3:
            anomaly_ratio = (anomaly_count / total_cuts * 100) if total_cuts > 0 else 0
            st.metric("ì´ìƒ ë¹„ìœ¨", f"{anomaly_ratio:.1f}%")
        with col4:
            avg_score = df_anomaly["score"].mean()
            st.metric("í‰ê·  ì´ìƒ ì ìˆ˜", f"{avg_score:.6f}")
        
        # ì´ìƒ ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ì„ ê²½ìš° ê²½ê³ 
        if anomaly_ratio >= 90:
            st.error(
                f"ğŸš¨ **ì‹¬ê°í•œ ë¬¸ì œ ë°œê²¬:** ì´ìƒ íƒì§€ ë¹„ìœ¨ì´ {anomaly_ratio:.1f}%ì…ë‹ˆë‹¤!\n\n"
                "**ì›ì¸ ë¶„ì„:**\n\n"
                "1. **í•™ìŠµ ë°ì´í„°**: ê° ì¡°ê±´(c1, c4, c6)ì˜ **ì²˜ìŒ 30ê°œ cut**ë§Œ ì‚¬ìš© (ì´ˆê¸° ì •ìƒ ìƒíƒœ)\n"
                "2. **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: ê° ì¡°ê±´ì˜ **ë§ˆì§€ë§‰ 50ê°œ cut** ì‚¬ìš© (ë§ˆëª¨ ì§„í–‰ëœ í›„ë°˜ë¶€)\n"
                "3. **ê²°ê³¼**: ë§ˆëª¨ ì§„í–‰ëœ ë°ì´í„°ëŠ” ì •ìƒ íŒ¨í„´ê³¼ ë‹¤ë¥´ë¯€ë¡œ ëª¨ë‘ ì´ìƒìœ¼ë¡œ íŒë‹¨ë¨\n\n"
                "**ì´ê²ƒì€ ì •ìƒì ì¸ ë™ì‘ì…ë‹ˆë‹¤!** ë§ˆëª¨ê°€ ì§„í–‰ëœ ë°ì´í„°ëŠ” ì‹¤ì œë¡œ ì •ìƒ ìƒíƒœê°€ ì•„ë‹ˆë¯€ë¡œ "
                "ì´ìƒìœ¼ë¡œ íƒì§€ë˜ëŠ” ê²ƒì´ ë§ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ì´ëŠ” **ê³ ì¥ ì˜ˆì¸¡**ì˜ ëª©ì ì´ì§€ "
                "**ì´ˆê¸° ì´ìƒ íƒì§€**ì˜ ëª©ì ê³¼ëŠ” ë‹¤ë¦…ë‹ˆë‹¤.\n\n"
                "**í•´ê²° ë°©ë²•:**\n"
                "- ì´ˆê¸° ì´ìƒ íƒì§€ê°€ ëª©ì ì´ë¼ë©´: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ì´ˆê¸° ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©\n"
                "- ë§ˆëª¨ ì§„í–‰ ëª¨ë‹ˆí„°ë§ì´ ëª©ì ì´ë¼ë©´: í˜„ì¬ ê²°ê³¼ê°€ ì •ìƒ (ë§ˆëª¨ ì§„í–‰ = ì´ìƒ ìƒíƒœ)\n"
                "- ë” ì •í™•í•œ ë¶„ì„ì„ ì›í•œë‹¤ë©´: í•™ìŠµ ë°ì´í„°ì— ë‹¤ì–‘í•œ ìƒíƒœ(ì´ˆê¸°+ì¤‘ê°„+í›„ë°˜) í¬í•¨"
            )
        elif anomaly_ratio <= 10:
            st.info(
                f"â„¹ï¸ ì´ìƒ íƒì§€ ë¹„ìœ¨ì´ {anomaly_ratio:.1f}%ë¡œ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. "
                "ì„ê³„ê°’ì´ ë„ˆë¬´ ë†’ê±°ë‚˜ ëª¨ë¸ì´ ë„ˆë¬´ ë³´ìˆ˜ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        # ì¡°ê±´ë³„ ë¶„ì„
        st.subheader("4. ì¡°ê±´ë³„ ì´ìƒ íƒì§€ í†µê³„")
        condition_stats = df_anomaly.groupby("condition").agg({
            "score": ["mean", "std", "min", "max"],
            "is_anomaly": "sum",
            "cut": "count"
        }).round(6)
        condition_stats.columns = ["í‰ê·  ì ìˆ˜", "í‘œì¤€í¸ì°¨", "ìµœì†Œê°’", "ìµœëŒ€ê°’", "ì´ìƒ ìˆ˜", "ì´ Cut ìˆ˜"]
        st.dataframe(condition_stats, width="stretch")
        
        # ì´ìƒ ì ìˆ˜ ë¶„í¬
        st.subheader("5. ì´ìƒ ì ìˆ˜ ë¶„í¬")
        fig_dist = px.histogram(
            df_anomaly,
            x="score",
            nbins=30,
            title="ì´ìƒ ì ìˆ˜ íˆìŠ¤í† ê·¸ë¨",
            labels={"score": "ì´ìƒ ì ìˆ˜", "count": "ë¹ˆë„"},
        )
        fig_dist.add_vline(
            x=threshold,
            line_dash="dash",
            line_color="red",
            annotation_text=f"ì„ê³„ê°’: {threshold:.6f}",
        )
        fig_dist.update_layout(height=400)
        st.plotly_chart(fig_dist, width="stretch")
        
        # ì¡°ê±´ë³„ ë¹„êµ
        st.subheader("6. ì¡°ê±´ë³„ ì´ìƒ ì ìˆ˜ ë¹„êµ")
        fig_box = px.box(
            df_anomaly,
            x="condition",
            y="score",
            title="ì¡°ê±´ë³„ ì´ìƒ ì ìˆ˜ ë¶„í¬",
            labels={"condition": "ì¡°ê±´", "score": "ì´ìƒ ì ìˆ˜"},
        )
        fig_box.add_hline(
            y=threshold,
            line_dash="dash",
            line_color="red",
            annotation_text=f"ì„ê³„ê°’: {threshold:.6f}",
        )
        fig_box.update_layout(height=400)
        st.plotly_chart(fig_box, width="stretch")


def render_rul_prediction_section(diagnostics_data: dict, analysis_data: dict, models_dir: Path, figures_dir: Path):
    """ê³ ì¥ ì˜ˆì¸¡ ë¶„ì„ ì„¹ì…˜"""
    st.header("ğŸ”® ê³ ì¥ ì˜ˆì¸¡ (RUL) ë¶„ì„")
    
    st.subheader("1. RUL ì˜ˆì¸¡ ëª¨ë¸ ê°œìš”")
    
    rul_data = diagnostics_data.get("rul", {})
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì˜ˆì¸¡ ë‚¨ì€ ìˆ˜ëª…", f"{rul_data.get('cuts', 0):.1f} ì»·")
    with col2:
        st.metric("ì˜ˆì¸¡ ë²”ìœ„ (ìµœì†Œ)", f"{rul_data.get('min_cuts', 0):.1f} ì»·")
    with col3:
        st.metric("ì˜ˆì¸¡ ë²”ìœ„ (ìµœëŒ€)", f"{rul_data.get('max_cuts', 0):.1f} ì»·")
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    feature_importance = analysis_data.get("feature_importance", [])
    if feature_importance:
        st.subheader("2. RUL ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì£¼ìš” íŠ¹ì„±")
        st.markdown(
            "ê³ ì¥ ì˜ˆì¸¡ ëª¨ë¸ì€ ë‹¤ìŒ íŠ¹ì„±ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ë‚¨ì€ ìˆ˜ëª…ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. "
            "íŠ¹ì„± ì¤‘ìš”ë„ê°€ ë†’ì„ìˆ˜ë¡ ì˜ˆì¸¡ì— ë” í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤."
        )
        df_feat = pd.DataFrame(feature_importance)
        fig_feat = px.bar(
            df_feat,
            x="importance",
            y="feature",
            orientation="h",
            title="íŠ¹ì„± ì¤‘ìš”ë„ Top 5",
            labels={"importance": "ì¤‘ìš”ë„", "feature": "íŠ¹ì„±"},
            color="importance",
            color_continuous_scale="Blues",
        )
        fig_feat.update_layout(height=400, yaxis={"categoryorder": "total ascending"})
        st.plotly_chart(fig_feat, width="stretch")
        
        # íŠ¹ì„± ì„¤ëª…
        st.markdown("**ì£¼ìš” íŠ¹ì„± ì„¤ëª…:**")
        feature_descriptions = {
            "vz_rms": "Zì¶• ì§„ë™ì˜ RMS (Root Mean Square) ê°’ - ì§„ë™ ì—ë„ˆì§€ì˜ í¬ê¸°",
            "vz_std": "Zì¶• ì§„ë™ì˜ í‘œì¤€í¸ì°¨ - ì§„ë™ ë³€ë™ì„±",
            "sy_rms": "Yì¶• í˜ì˜ RMS ê°’ - ê°€ê³µë ¥ì˜ í¬ê¸°",
            "sy_std": "Yì¶• í˜ì˜ í‘œì¤€í¸ì°¨ - ê°€ê³µë ¥ ë³€ë™ì„±",
            "sx_max": "Xì¶• í˜ì˜ ìµœëŒ€ê°’ - ìµœëŒ€ ê°€ê³µë ¥",
        }
        for feat in df_feat["feature"].head(5):
            desc = feature_descriptions.get(feat, "ì„¼ì„œ ë°ì´í„° í†µê³„ íŠ¹ì„±")
            st.markdown(f"- **{feat}**: {desc}")
    
    # ë§ˆëª¨ ë¶„ì„
    wear_data = diagnostics_data.get("wear", {})
    if wear_data:
        st.subheader("3. ë§ˆëª¨ ì§„í–‰ ë¶„ì„")
        st.markdown(
            "ë§ˆëª¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³µêµ¬ì˜ ìƒíƒœë¥¼ ë¶„ì„í•˜ê³ , "
            "ì˜ˆì¸¡ ëª¨ë¸ì´ ì´ë¥¼ í™œìš©í•˜ì—¬ ë‚¨ì€ ìˆ˜ëª…ì„ ê³„ì‚°í•©ë‹ˆë‹¤."
        )
        
        actual_series = wear_data.get("actual_series", [])
        predicted_series = wear_data.get("predicted_series", [])
        
        col1, col2 = st.columns(2)
        with col1:
            current_wear = wear_data.get("current", 0.0)
            max_limit = wear_data.get("max_limit", 200.0)
            ratio = wear_data.get("ratio_percent", 0.0)
            st.metric("í˜„ì¬ ë§ˆëª¨ëŸ‰", f"{current_wear:.2f}")
            st.metric("ë§ˆëª¨ í•œê³„", f"{max_limit:.1f}")
            st.metric("ë§ˆëª¨ìœ¨", f"{ratio:.1f}%")
        
        with col2:
            st.info(
                f"**ë¶„ì„ ê²°ê³¼:**\n\n"
                f"- í˜„ì¬ ë§ˆëª¨ëŸ‰ì€ í•œê³„ì˜ {ratio:.1f}%ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.\n"
                f"- ì˜ˆì¸¡ëœ ë‚¨ì€ ìˆ˜ëª…: {rul_data.get('cuts', 0):.1f} ì»·\n"
                f"- ì˜ˆìƒ ê³ ì¥ ì‹œê°: {rul_data.get('predicted_failure_time', 'N/A')[:19] if rul_data.get('predicted_failure_time') else 'N/A'}"
            )
        
        # ë§ˆëª¨ ì‹œê³„ì—´
        if actual_series or predicted_series:
            fig_wear = go.Figure()
            if actual_series:
                df_actual = pd.DataFrame(actual_series)
                wear_col = "wear" if "wear" in df_actual.columns else df_actual.columns[1] if len(df_actual.columns) > 1 else None
                if wear_col:
                    fig_wear.add_trace(
                        go.Scatter(
                            x=df_actual["cut"],
                            y=df_actual[wear_col],
                            mode="lines+markers",
                            name="ì‹¤ì œ ë§ˆëª¨",
                            line=dict(color="blue", width=2),
                        )
                    )
            if predicted_series:
                df_pred = pd.DataFrame(predicted_series)
                wear_col = "wear" if "wear" in df_pred.columns else ("prediction" if "prediction" in df_pred.columns else df_pred.columns[1] if len(df_pred.columns) > 1 else None)
                if wear_col:
                    fig_wear.add_trace(
                        go.Scatter(
                            x=df_pred["cut"],
                            y=df_pred[wear_col],
                            mode="lines+markers",
                            name="ì˜ˆì¸¡ ë§ˆëª¨",
                            line=dict(color="red", dash="dash", width=2),
                        )
                    )
            if max_limit:
                fig_wear.add_hline(
                    y=max_limit,
                    line_dash="dash",
                    line_color="orange",
                    annotation_text=f"í•œê³„: {max_limit:.1f}",
                )
            fig_wear.update_layout(
                title="ë§ˆëª¨ ì§„í–‰ ì¶”ì´ (ì‹¤ì œ vs ì˜ˆì¸¡)",
                xaxis_title="Cut ë²ˆí˜¸",
                yaxis_title="ë§ˆëª¨ëŸ‰",
                height=500,
            )
            st.plotly_chart(fig_wear, width="stretch")
    
    # ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ
    metrics_path = figures_dir / "rul_metrics.csv"
    if metrics_path.exists():
        st.subheader("4. ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
        df_metrics = pd.read_csv(metrics_path)
        st.dataframe(df_metrics, width="stretch", hide_index=True)


def render_correlation_analysis(analysis_data: dict):
    """ìƒê´€ê´€ê³„ ë¶„ì„ ì„¹ì…˜"""
    st.header("ğŸ”— ì„¼ì„œ ìƒê´€ê´€ê³„ ë¶„ì„")
    
    correlation_matrix = analysis_data.get("correlation_matrix", [])
    if correlation_matrix:
        st.markdown(
            "ì„¼ì„œ ê°„ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì„¼ì„œë“¤ì´ í•¨ê»˜ ë³€í™”í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. "
            "ì´ëŠ” ì´ìƒ íƒì§€ì™€ ê³ ì¥ ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        )
        
        if isinstance(correlation_matrix, list) and len(correlation_matrix) > 0:
            if isinstance(correlation_matrix[0], dict):
                df_corr = pd.DataFrame(correlation_matrix)
            else:
                df_corr = pd.DataFrame(correlation_matrix)
            
            if not df_corr.empty:
                fig_corr = px.imshow(
                    df_corr,
                    title="ì„¼ì„œ ìƒê´€ í–‰ë ¬",
                    aspect="auto",
                    color_continuous_scale="RdBu",
                    labels=dict(color="ìƒê´€ê³„ìˆ˜"),
                )
                fig_corr.update_layout(height=600)
                st.plotly_chart(fig_corr, width="stretch")
    
    comparison_table = analysis_data.get("comparison_table", [])
    if comparison_table:
        st.subheader("ì •ìƒ vs ìœ„í—˜ êµ¬ê°„ ë¹„êµ")
        st.markdown("ì •ìƒ êµ¬ê°„ê³¼ ìœ„í—˜ êµ¬ê°„ì˜ ì„¼ì„œ íŠ¹ì„±ì„ ë¹„êµí•˜ì—¬ ì´ìƒ íŒ¨í„´ì„ íŒŒì•…í•©ë‹ˆë‹¤.")
        df_comp = pd.DataFrame(comparison_table)
        st.dataframe(df_comp, width="stretch")


def render_summary_section(monitoring_data: dict, diagnostics_data: dict):
    """ì¢…í•© ìš”ì•½ ì„¹ì…˜"""
    st.header("ğŸ“‹ ì¢…í•© ë¶„ì„ ìš”ì•½")
    
    current = monitoring_data.get("current_state", {})
    rul_data = diagnostics_data.get("rul", {})
    wear_data = diagnostics_data.get("wear", {})
    
    st.subheader("í˜„ì¬ ìƒíƒœ")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("**ì´ìƒ íƒì§€ ê²°ê³¼**")
        danger_level = current.get("danger_level", "unknown")
        st.metric("ìœ„í—˜ ìˆ˜ì¤€", danger_level)
        st.metric("ì´ìƒ ì ìˆ˜", f"{current.get('current_anomaly_score', 0):.6f}")
    with col2:
        st.markdown("**ê³ ì¥ ì˜ˆì¸¡ ê²°ê³¼**")
        st.metric("ë‚¨ì€ ìˆ˜ëª…", f"{rul_data.get('cuts', 0):.1f} ì»·")
        st.metric("ì˜ˆìƒ ê³ ì¥ ì‹œê°", rul_data.get("predicted_failure_time", "N/A")[:19] if rul_data.get("predicted_failure_time") else "N/A")
    with col3:
        st.markdown("**ë§ˆëª¨ ìƒíƒœ**")
        st.metric("í˜„ì¬ ë§ˆëª¨ìœ¨", f"{wear_data.get('ratio_percent', 0):.1f}%")
        st.metric("ë§ˆëª¨ í•œê³„", f"{wear_data.get('max_limit', 0):.1f}")
    
    st.divider()
    
    st.subheader("ë¶„ì„ ë°©ë²•ë¡ ")
    st.markdown("""
    ### ì´ìƒ íƒì§€ ë°©ë²•
    1. **LSTM Autoencoder ëª¨ë¸**ì„ ì‚¬ìš©í•˜ì—¬ ì •ìƒ ìƒíƒœì˜ ì§„ë™ íŒ¨í„´ì„ í•™ìŠµ
    2. ìƒˆë¡œìš´ ë°ì´í„°ì˜ **ì¬êµ¬ì„± ì˜¤ì°¨**ë¥¼ ê³„ì‚°í•˜ì—¬ ì´ìƒ ì—¬ë¶€ íŒë‹¨
    3. ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ì´ìƒìœ¼ë¡œ ë¶„ë¥˜
    
    ### ê³ ì¥ ì˜ˆì¸¡ ë°©ë²•
    1. ì„¼ì„œ ë°ì´í„°ì—ì„œ **í†µê³„ì  íŠ¹ì„±** ì¶”ì¶œ (RMS, í‘œì¤€í¸ì°¨, ìµœëŒ€ê°’ ë“±)
    2. **Random Forest íšŒê·€ ëª¨ë¸**ì„ ì‚¬ìš©í•˜ì—¬ ë§ˆëª¨ëŸ‰ê³¼ ë‚¨ì€ ìˆ˜ëª… ì˜ˆì¸¡
    3. **êµì°¨ ê²€ì¦**ì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    
    ### ë°ì´í„° í™œìš©
    - **ì§„ë™ ì„¼ì„œ (vx, vy, vz)**: ì´ìƒ íƒì§€ì˜ ì£¼ìš” ì…ë ¥
    - **í˜ ì„¼ì„œ (sx, sy, sz)**: ê³ ì¥ ì˜ˆì¸¡ì˜ ë³´ì¡° íŠ¹ì„±
    - **ë§ˆëª¨ ë°ì´í„°**: ì˜ˆì¸¡ ëª¨ë¸ì˜ í•™ìŠµ ë° ê²€ì¦ì— ì‚¬ìš©
    """)


def main():
    st.title("ğŸ“ˆ VibraCNC ë¶„ì„ ë¦¬í¬íŠ¸")
    st.markdown("ì´ìƒ íƒì§€ì™€ ê³ ì¥ ì˜ˆì¸¡ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”: íŒŒì¼ ê²½ë¡œ ì„¤ì •
    with st.sidebar:
        st.header("ì„¤ì •")
        monitoring_path = Path(
            st.text_input(
                "ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ê²½ë¡œ",
                value=str(DEFAULT_MONITORING_PATH),
            )
        )
        diagnostics_path = Path(
            st.text_input(
                "ì§„ë‹¨ ë¦¬í¬íŠ¸ ê²½ë¡œ",
                value=str(DEFAULT_DIAGNOSTICS_PATH),
            )
        )
        analysis_path = Path(
            st.text_input(
                "ë¶„ì„ ë¦¬í¬íŠ¸ ê²½ë¡œ",
                value=str(DEFAULT_ANALYSIS_PATH),
            )
        )
        models_dir = Path(
            st.text_input(
                "ëª¨ë¸ ë””ë ‰í„°ë¦¬",
                value=str(DEFAULT_MODELS_DIR),
            )
        )
        figures_dir = Path(
            st.text_input(
                "ê²°ê³¼ ë””ë ‰í„°ë¦¬",
                value=str(DEFAULT_FIGURES_DIR),
            )
        )
        st.subheader("ì •ì  ë¶„ì„ ì„¤ì •")
        dataset_dir = Path(
            st.text_input(
                "ë°ì´í„°ì…‹ ê²½ë¡œ",
                value=str(DEFAULT_DATASET_DIR),
            )
        )
        static_condition = st.selectbox(
            "ë¶„ì„ ì¡°ê±´",
            options=["c1", "c2", "c3", "c4", "c5", "c6"],
            index=1,
        )
        num_cuts = st.slider("ë¶„ì„í•  Cut ìˆ˜", min_value=10, max_value=200, value=60, step=5)
        sampling_rate = st.number_input("ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)", value=25600.0, step=100.0)
        window_seconds = st.number_input("ìœˆë„ìš° ê¸¸ì´ (ì´ˆ)", value=0.1, step=0.01, format="%.3f")
        step_seconds = st.number_input("ìœˆë„ìš° ìŠ¤í… (ì´ˆ)", value=0.05, step=0.01, format="%.3f")
        selected_cut = st.number_input(
            "FFT ë¶„ì„ Cut ë²ˆí˜¸",
            min_value=1,
            max_value=num_cuts,
            value=num_cuts,
            step=1,
        )
        freq_band = st.slider(
            "ê°•ì¡°í•  ì£¼íŒŒìˆ˜ ëŒ€ì—­ (Hz)",
            min_value=0,
            max_value=5000,
            value=(100, 300),
            step=50,
        )
    
    # ì •ì  ë¶„ì„ ë°ì´í„° ì¤€ë¹„
    try:
        static_records, static_threshold = load_static_condition_data(
            str(dataset_dir),
            str(models_dir),
            static_condition,
            num_cuts,
            sampling_rate,
            window_seconds,
            step_seconds,
        )
    except FileNotFoundError as exc:
        st.error(f"ì •ì  ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exc}")
        static_records, static_threshold = [], 0.0

    fft_payload = None
    if static_records:
        fft_payload = compute_fft_spectrum(
            str(dataset_dir),
            static_condition,
            int(selected_cut),
            sampling_rate,
            window_seconds,
            step_seconds,
            ("vx", "vy", "vz"),
        )

    render_static_condition_section(
        records=static_records,
        threshold=static_threshold,
        condition=static_condition,
        fft_payload=fft_payload,
        selected_cut=int(selected_cut),
        freq_band=freq_band,
    )

    st.divider()

    # ë°ì´í„° ë¡œë“œ
    monitoring_data = load_json(monitoring_path)
    diagnostics_data = load_json(diagnostics_path)
    analysis_data = load_json(analysis_path)
    
    if not monitoring_data:
        st.error(f"ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {monitoring_path}")
        return
    
    if not diagnostics_data:
        st.error(f"ì§„ë‹¨ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {diagnostics_path}")
        return
    
    if not analysis_data:
        st.error(f"ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {analysis_path}")
        return
    
    # ì„¹ì…˜ ë Œë”ë§
    render_summary_section(monitoring_data, diagnostics_data)
    st.divider()
    render_anomaly_detection_section(monitoring_data, models_dir)
    st.divider()
    render_rul_prediction_section(diagnostics_data, analysis_data, models_dir, figures_dir)
    st.divider()
    render_correlation_analysis(analysis_data)


if __name__ == "__main__":
    main()

